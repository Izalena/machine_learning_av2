{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8e6IcCsJCxVz"
   },
   "source": [
    "DISCIPLINA: Gestão do Conhecimento\t PROFESSOR(A): Alex Salgado\n",
    "PERÍODO: 7o. TURNO: noite AVALIAÇÃO:\n",
    "\n",
    "ALUNO(A): _\n",
    "\n",
    "GRAU: VISTO DO PROFESSOR:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3h1pahVCxV2"
   },
   "source": [
    "# Questão 1 - valor (1,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-cj5d2rCxV3"
   },
   "source": [
    "*** Crie um repositório no Github e adicione este arquivo no mesmo\n",
    "\n",
    "\n",
    "1.1 - Você deve escolher uma base de dados aberta que seja possível treinar um modelo de aprendizagem de máquina Supervisionado de Classificação (assim como o exemplo da Iris e Cancer). A partir desta base de dados, você vai treinar o modelo, fazer previsões e calcular a acurácia do mesmo.\n",
    "Obs.: Não utilizar nenhuma base de dados usada em aula ou nos trabalhos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3P5uSWxsDb5r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWD182zJCxV4"
   },
   "outputs": [],
   "source": [
    "https://github.com/Izalena/machine_learning_av2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-D7KRIzCxV8"
   },
   "source": [
    "1.2 - Após tratada, criar uma pasta no seu GoogleDrive e disponibilizar o link do arquivo de sua base (csv, xlsx, etc) para ser importado no seu código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lT8fVn5TCxV8"
   },
   "outputs": [],
   "source": [
    "https://drive.google.com/file/d/1E_XTl2VaaOZqBAW-AQGF9K3J1Hicqqvo/view?usp=sharing / https://drive.google.com/file/d/1FlmF81gWhWi7H_NO9c9-youTvmmSPRZR/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvPXgDBDCxV_"
   },
   "source": [
    "## Criar um código usando o Jupyter Notebook e responder (através de código) às seguintes questões:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMkAEsOKCxWA"
   },
   "source": [
    "# Questão 2 - valor (1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yOSNQel0CxWA"
   },
   "source": [
    "2.1 - Importar os modulos python para machine learn e carregar o arquivo \n",
    "\n",
    "** Sugestão se for do tipo xlsx, usar o read_excel do pandas\n",
    "import pandas as pd\n",
    "dt = pd.read_excel(\"meuarquivo.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zA6l-qg9CxWB"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17a815014e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train = pd.read_csv('data/train.csv', encoding='latin-1')\n",
    "test = pd.read_csv('data/test.csv', encoding='latin-1')\n",
    "\n",
    "train.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROM2Hy1CCxWG"
   },
   "source": [
    "2.3 - De que se trata esse banco de dados? e que tipo de previsão pode ser feito com ele?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xh68K5SjCxWH"
   },
   "outputs": [],
   "source": [
    "São publicações feitas no twitter, os \"twits\". O objetivo é fazer uma análise de sentimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lCf85KKCxWJ"
   },
   "source": [
    "# Questão 3 - valor (0,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isyZsq2NCxWK"
   },
   "source": [
    "Utilizando as terminologias de Machine Learning(features e observações):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbuaWyeECxWL"
   },
   "source": [
    "3.1 - Quantas \"features\" têm nessa base de dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MY5Xwd0gCxWL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtwxkASmCxWN"
   },
   "source": [
    "3.2 - Quantas observações têm nessa base de dados?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yN1QNvh-CxWO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AudYWfr1CxWQ"
   },
   "source": [
    "# Questão 4 - valor (1,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJxRMc1HCxWR"
   },
   "source": [
    "4.1 - Faça uma previsão, usando o algoritmo de LogisticRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu7ZKtSkCxWS"
   },
   "outputs": [],
   "source": [
    "#Pegar as palavras importantes.\n",
    "twits = [\n",
    "    'This is amazing!',\n",
    "    'ML is the best, yes it is',\n",
    "    'I am not sure about how this is going to end...'\n",
    "]\n",
    "\n",
    "# Armazena as palavras em um dicionário que mapeia as palavras a seus índices.\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(twits)\n",
    "\n",
    "count.vocabulary_\n",
    "bag.toarray()\n",
    "\n",
    "# Relevância das palavras\n",
    "# É possível \"ranquear\" as palavras, por exemplo, \"is\" tem menos relevância que \"happy\".\n",
    "tfidf = TfidfTransformer(use_idf=True,\n",
    "                         norm='l2',\n",
    "                         smooth_idf=True)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "tfidf.fit_transform(bag).toarray()\n",
    "\n",
    "##Limpando palavras que não são importantes\n",
    "\n",
    "vocab = Counter()\n",
    "for twit in train.SentimentText:\n",
    "    for word in twit.split(' '):\n",
    "        vocab[word] += 1\n",
    "\n",
    "vocab.most_common(20)\n",
    "output_notebook()\n",
    "\n",
    "def plot_distribution(vocabulary):\n",
    "\n",
    "    hist, edges = np.histogram(list(map(lambda x:math.log(x[1]),vocabulary.most_common())), density=True, bins=500)\n",
    "\n",
    "    p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "               toolbar_location=\"above\",\n",
    "               title=\"Word distribution accross all twits\")\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\", )\n",
    "    show(p)\n",
    "\n",
    "plot_distribution(vocab)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "vocab_reduced = Counter()\n",
    "for w, c in vocab.items():\n",
    "    if not w in stop:\n",
    "        vocab_reduced[w]=c\n",
    "\n",
    "vocab_reduced.most_common(20)\n",
    "\n",
    "## finalmente treinando o algoritmo de Logistic Regression\n",
    "# separar as duas databases\n",
    "X = train['SentimentText']\n",
    "y = train['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__preprocessor': [None, preprocessor],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__preprocessor': [None, preprocessor],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Melhor parameter set: ' + str(gs_lr_tfidf.best_params_))\n",
    "print('Melhor Acurácia: %.3f' % gs_lr_tfidf.best_score_)\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Acurácia em teste: %.3f' % clf.score(X_test, y_test))\n",
    "pickle.dump(clf, open(os.path.join('data', 'logisticRegression.pkl'), 'wb'), protocol=4)\n",
    "\n",
    "twits = [\n",
    "    \"This is really bad, I don't like it at all\",\n",
    "    \"I love this!\",\n",
    "    \":)\",\n",
    "    \"I'm sad... :(\"\n",
    "]\n",
    "\n",
    "preds = clf.predict(twits)\n",
    "\n",
    "for i in range(len(twits)):\n",
    "    print(f'{twits[i]} --> {preds[i]}')\n",
    "    \n",
    "\n",
    "    \n",
    "##### OBS:\n",
    "## Esse tutorial eu peguei no canal do Siraj Raval (Muito bom!)\n",
    "## https://www.youtube.com/watch?v=H6ii7NFdDeg\n",
    "\n",
    "## Não consegui fazer funcionar a tempo de entregar,\n",
    "## apesar de não parecer difícil exigiu um conhecimento mais aprofundado de python.\n",
    "## Meu objetivo é finalizar esse projeto, independente da matéria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbpLvAhTCxWU"
   },
   "source": [
    "# Questão 5 - valor (1,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp4fWsL7CxWU"
   },
   "source": [
    "Usando o método de avaliação de acurácia (Treinar e testar na base de dados inteira/Train test entire model), Calcular a acurácia de cada um dos 3 métodos abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C40t1F9ICxWV"
   },
   "source": [
    "4.1 - Acurácia usando o algoritmo de KNN (com 1 vizinho, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d5YPueDCxWW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNmy44xfCxWY"
   },
   "source": [
    "4.2 - Acurácia usando o algoritmo de KNN (com 5 vizinho, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caGkCtYGCxWY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3xUZm_JICxWa"
   },
   "source": [
    "4.3 - Acurácia usando o algoritmo de LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvAgNcVsCxWb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FkyIUHbCxWd"
   },
   "source": [
    "4.4 - De acordo com seus resultados anteriores, qual dos 3 métodos é mais eficiente?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0AE8XQ1CxWd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRDUIRloCxWf"
   },
   "outputs": [],
   "source": [
    "*** Envie o link do seu Github com essa resposta no Classroom\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Prova AV2 - Gestão do Conhecimento.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
